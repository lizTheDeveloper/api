runtime: python39
entrypoint: uvicorn llamaapi:api --host=0.0.0.0 --port=8080
instance_class: F1
automatic_scaling:
  target_cpu_utilization: 0.65
  min_instances: 1
  max_instances: 10